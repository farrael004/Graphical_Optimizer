{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaUUN0wQHm4D"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oHR1GGluHXdp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df1 = pd.read_csv('california_housing_test.csv')\n",
    "df1 =df1.dropna()\n",
    "X = df1.copy()\n",
    "X.pop('median_house_value')\n",
    "y = df1.median_house_value.copy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) #Create standardization and apply to train data\n",
    "X_test = sc.transform(X_test)       #Apply created standardization to new data\n",
    "X_val = sc.transform(X_val)         #Apply created standardization to new data\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, svd_solver='full')\n",
    "X_train = pca.fit_transform(X_train) #Create PCA and apply to train data\n",
    "X_test = pca.transform(X_test)       #Apply created PCA to new data\n",
    "X_val = pca.transform(X_val)         #Apply created normalization to new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Io0vfhBEVulX"
   },
   "source": [
    "# Creating model, predict and performance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "51oRdGyODRvj"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def ModelFunction(params, X_train, y_train):\n",
    "    gbr = GradientBoostingRegressor(n_estimators      = 6000,\n",
    "                                    learning_rate     = params['learning_rate'],\n",
    "                                    max_depth         = params['max_depth'],\n",
    "                                    max_features      = params['max_features'],\n",
    "                                    min_samples_leaf  = 10,\n",
    "                                    min_samples_split = 8,\n",
    "                                    random_state=42)\n",
    "\n",
    "    model = gbr.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def PredictFunction(model, X):\n",
    "    y_pred = model.predict(X)\n",
    "    return y_pred\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "def PerformanceFunction(y_test, y_pred):\n",
    "    model_mae = mean_absolute_error(y_test, y_pred)\n",
    "    model_mse = mean_squared_error(y_test, y_pred)\n",
    "    model_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    model_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    model_results = {\"Mean Absolute Error (MAE)\": model_mae,\n",
    "                     \"Mean Squared Error (MSE)\": model_mse,\n",
    "                     \"Root Mean Squared Error (RMSE)\": model_rmse,\n",
    "                     \"Adjusted R^2 Score\": model_r2}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIKhPozCVulY"
   },
   "source": [
    "# Function that will update table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yKRhJ2F6BE1r"
   },
   "outputs": [],
   "source": [
    "def print_status(self): # Shows the parameters used and accuracy attained of the search so far.\n",
    "        global app\n",
    "        results = pd.DataFrame(dict(self.scores, **self.params), index=[0])\n",
    "        app.table.model.df = pd.concat([app.table.model.df, results], ignore_index=True, axis=0)\n",
    "        \n",
    "        app.table.autoResizeColumns()\n",
    "        app.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaQWuPF-BTHG"
   },
   "source": [
    "# Custom Estimator wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MnAYvf5HBWh-"
   },
   "outputs": [],
   "source": [
    "from skopt.learning.gaussian_process.kernels import Hyperparameter\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "hyperparameters = {'n_estimators':      [5000,6000], # Upper and lower bounds\n",
    "                   'learning_rate':     [0.001,0.01], # Upper and lower bounds\n",
    "                   'max_depth':         [2,6], # Upper and lower bounds\n",
    "                   'max_features':      ['sqrt','log2','auto'], # Categorical bounds\n",
    "                   'min_samples_leaf':  [1,21], # Upper and lower bounds\n",
    "                   'min_samples_split': [1,16],} # Upper and lower bounds\n",
    "\n",
    "class WrapperEstimator(BaseEstimator):\n",
    "    def __init__(self, learning_rate=0.1, max_depth=4, max_features='sqrt'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.variables = hyperparameters\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.params = {\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'max_depth': self.max_depth,\n",
    "            'max_features': self.max_features\n",
    "        }\n",
    "\n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "\n",
    "        self.model = ModelFunction(self.params, X, y)\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        prediction = PredictFunction(self.model,X)\n",
    "        return prediction\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        model = self.model\n",
    "        y_pred = self.predict(X)\n",
    "        self.scores = PerformanceFunction(y, y_pred)\n",
    "        print_status(self)\n",
    "        return self.scores['Adjusted R^2 Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6j1n8x6WjYr"
   },
   "source": [
    "# Optimizer types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YZZl2iiWoCw"
   },
   "source": [
    "## Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kQgftafaVulR"
   },
   "outputs": [],
   "source": [
    "def BayesianOpt(X_train, y_train):\n",
    "    global app\n",
    "\n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    from skopt import BayesSearchCV\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "    WrapperEstimator().set_params()\n",
    "    \n",
    "    bayReg = BayesSearchCV(\n",
    "        WrapperEstimator(),\n",
    "        {\n",
    "            'n_estimators':      Real(5000,6000),\n",
    "            'learning_rate':     Real(0.001,0.01),\n",
    "            'max_depth':         Integer(2,6),\n",
    "            'max_features':      Categorical(['sqrt','log2','auto']),\n",
    "            'min_samples_leaf':  Integer(1,21),\n",
    "            'min_samples_split': Integer(1,16),\n",
    "        },\n",
    "        random_state = 42 ,\n",
    "        verbose = 0,\n",
    "        n_iter = 100 ,\n",
    "        cv = 2 ,\n",
    "        n_jobs = 1 ,\n",
    "        n_points = 2\n",
    "    )\n",
    "\n",
    "    model1 = bayReg.fit(X_train, y_train) # Included callback function that is called after every iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcpfMSTbWs1d"
   },
   "source": [
    "## Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m8uLpdaZWwTE"
   },
   "outputs": [],
   "source": [
    "def GridOpt(X_train, y_train):\n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        WrapperEstimator(),\n",
    "        {\n",
    "            'max_features': ['sqrt','log2'] ,\n",
    "            'learning_rate': np.linspace(0.1,0.3,10) ,\n",
    "            'max_depth': range(3,7) ,\n",
    "        },\n",
    "        verbose = 0,\n",
    "        cv = 2 ,\n",
    "        n_jobs = 1 ,\n",
    "    )\n",
    "    grid.cv_results_ = {}\n",
    "    model1 = grid.fit(X_train, y_train) # Included callback function that is called after every iteration\n",
    "\n",
    "    app.table.model.df = pd.DataFrame(grid.cv_results_).drop(['params'], axis=1)\n",
    "    app.table.autoResizeColumns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjyuCP0fWufm"
   },
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Iw0JU1RvWwC-"
   },
   "outputs": [],
   "source": [
    "def RandomOpt(X_train, y_train):    \n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "    randomSearch = RandomizedSearchCV(\n",
    "        WrapperEstimator(),\n",
    "        {\n",
    "            'max_features': ['sqrt','log2'] ,\n",
    "            'learning_rate': np.linspace(0.1,0.3,10) ,\n",
    "            'max_depth': range(3,7) ,\n",
    "        },\n",
    "        random_state = 42 ,\n",
    "        verbose = 0,\n",
    "        n_iter = 10 ,\n",
    "        cv = 2 ,\n",
    "        n_jobs = 2 ,\n",
    "    )\n",
    "\n",
    "    model1 = randomSearch.fit(X_train, y_train) # Included callback function that is called after every iteration\n",
    "\n",
    "    app.table.model.df = pd.DataFrame(randomSearch.cv_results_).drop(['params'], axis=1)\n",
    "    app.table.autoResizeColumns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iitVosAuH4vT"
   },
   "source": [
    "# Creating app class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "G9SvA4ZxWlZ-"
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from pandastable import Table, TableModel, config\n",
    "import threading\n",
    "\n",
    "class App(Frame, threading.Thread):\n",
    "        def __init__(self, parent=None):\n",
    "            self.parent = parent\n",
    "            threading.Thread.__init__(self)\n",
    "            self.start()\n",
    "            \n",
    "        def callback(self):\n",
    "            self.root.quit()\n",
    "            \n",
    "        def run(self):\n",
    "            Frame.__init__(self)\n",
    "            self.main = self.master\n",
    "            self.main.geometry('600x400+200+100')\n",
    "            self.main.title('Optimizer')\n",
    "            self.f = Frame(self.main)\n",
    "            self.f.pack(fill=BOTH,expand=1)\n",
    "            df = pd.DataFrame()\n",
    "            self.table = pt = Table(self.f, dataframe=df,\n",
    "                                    showtoolbar=True, showstatusbar=True)\n",
    "            pt.show() \n",
    "            options = {'colheadercolor':'green','floatprecision': 5} # set some options\n",
    "            config.apply_options(options, pt)\n",
    "            pt.show()\n",
    "\n",
    "            self.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8eu_Y7mWMLS"
   },
   "source": [
    "# Running app (Not compatible with colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "1zfYXCLgWLbd",
    "outputId": "2d9f78a2-855d-41dc-b563-82385895180f"
   },
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Rafael\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 153, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"C:\\Users\\Rafael\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 271, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\Rafael\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 264, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\Rafael\\anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py\", line 602, in dump\n    return Pickler.dump(self, obj)\nTypeError: cannot pickle '_thread.lock' object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     RandomOpt(X_train, y_train)\n\u001b[0;32m     10\u001b[0m app \u001b[38;5;241m=\u001b[39m App()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mrandom\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom\u001b[39m():\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mRandomOpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mRandomOpt\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingRegressor\n\u001b[0;32m      6\u001b[0m randomSearch \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m      7\u001b[0m     WrapperEstimator(),\n\u001b[0;32m      8\u001b[0m     {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m ,\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mrandomSearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Included callback function that is called after every iteration\u001b[39;00m\n\u001b[0;32m     22\u001b[0m app\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(randomSearch\u001b[38;5;241m.\u001b[39mcv_results_)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m app\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mautoResizeColumns()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1765\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1766\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "def bayesian():\n",
    "    BayesianOpt(X_train, y_train)\n",
    "\n",
    "def grid():\n",
    "    GridOpt(X_train, y_train)\n",
    "\n",
    "def random():\n",
    "    RandomOpt(X_train, y_train)\n",
    "\n",
    "app = App()\n",
    "\n",
    "random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQaNrfrVePZY"
   },
   "source": [
    "# To Do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO5ygUIiePZY"
   },
   "source": [
    "1 - Dynamically adding hyperparameters to wrapper\n",
    "\n",
    "2 - Parallel compatibility\n",
    "\n",
    "3 - Column sizing\n",
    "\n",
    "4 - Implement all scores on final table"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('graphical_optimizer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7c0d3bb6a7871e53873bc4f685e6ff9456bd483d6ec0353bcafb12e5e0cf742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
